 GPT-4 takes what you prompt it with and just runs with it. From one perspective, it's a tool. A thing you can use to get useful tasks done in language. From another perspective, it's a system that can make dreams, thoughts, ideas, flourish in text in front of you. GPT-4 is incredibly advanced and sophisticated. It can take in and generate up to 25,000 words of text around eight times more than chat GPT. It understands images and can express logical ideas about them. For example, it can tell us that if the strings in this image were cut, the balloons would fly away. This is the place where you just get turbocharged by these AIs. They're not perfect. They make mistakes, and so you really need to make sure that you know the work is being done to your level of expectation. But I think that it is fundamentally about amplifying what every person is able to do. GPT-4 training finished last August, and everything that's been happening in the past few months up until we've released it has been a giant sprint make it see for more aligned and also more useful. We have put in already a lot of internal guardrails around things like adversarial usage, unwanted content, and private-seek concerns. And when we release a model, we know things are not done. We know we have to learn, we know we have to update, we know we have to keep improving all the systems around it to make it suitable for society. To me, the most compelling use cases of these technologies will come from starting with a real human need. The obvious one where the systems have really incredible potential is in education. GPT-4 can teach a huge range of subjects. Imagine giving a fifth grader a personal math tutor with unlimited time and patience. It's a great tool to bring learning to everyone in a way that is personalized to their skill level. GPT-4 brings the dream of having the most useful, helpful, assistant to life. It's really about adding as much value to everyday life as possible. The partnership that OpenAI has with Microsoft is to shape this technology into something that's going to be useful for the world. The power of AI, hopefully, is that it can help us be more productive, which ultimately leads to better quality of life. The development of the transistor of the computer of the internet, the semiconductor industry, all the programming languages, everything came together to produce AI technology. And while it is very limited, it is already easy to imagine what the impact of a successor managed generations down the line will look like. We think that GPT-4 will be the world's first experience with a highly capable and advanced AI system. So we really care about this model being useful to everyone, not just the early adopters or people very close to technology. So it is really important to us that as many people as possible participate so that we can learn more about how it can be helpful to everyone. you

 Have you ever seen a polar bear playing bass? Or robot painted like a Picasso? Didn't think so. Dolly too is a new AI system from OpenAI that can take simple text descriptions like a Koala-Dunking Abaskable and turn them into photo-realistic images that have never existed before. Dolly too can also realistically edit and retouch photos. Based on a simple natural language description, it can fill in or replace part of an image with AI-generated imagery that blends seamlessly with the original. It's called in-painting. In January 2021, OpenAI introduced Dolly, a system that could generate images from text, like this avocado armchair. Dolly too takes the technology even further with higher resolution, greater comprehension, and new capabilities, like in-painting. It can even start with an image as an input and create variations with different angles and styles. Dolly was created by training a neural network on images and their text descriptions. Through deep learning, it not only understands individual objects, like koala bears and motorcycles, but learns from relationships between objects. And when you ask Dolly for an image of a koala bear riding a motorcycle, it knows how to create that or anything else with a relationship to another object or action. The Dolly research has three main outcomes. First, it can help people express themselves visually in ways they may not have been able to before. Second, an AI-generated image can tell us a lot about whether the system understands us or is just repeating what it's been taught. Third, Dolly helps humans understand how AI systems see and understand our world. This is a critical part of developing AI that's useful and safe. The technology is constantly evolving, and Dolly too has limitations. If it's taught with images that are incorrectly labeled, like a plain labeled car, and a user tries to generate a car, Dolly may create a plane. It's like talking to a person who learned the wrong word for something. Dolly can also be limited by gaps in its training. If you type that boon and Dolly has learned what a bad boon is through images and accurate labels, it will generate a lot of great bad boons. But if you type howler monkey, and it hasn't learned what a howler monkey is, Dolly will give you its best idea of what it thinks it could be, like a howling monkey. What's exciting about the approach used to train Dolly is that it can take what it learned from a variety of other labeled images and then apply it to the other object. And then apply it to a new image. Given a picture of a monkey, Dolly can infer what it would look like doing something it's never done before, like paying its taxes while wearing a funny hat. Dolly is an example of how imaginative humans and clever systems can work together to make new things, amplifying our creative potential.

