{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Support Question Answering Chatbot\n",
    "Implement a context-aware question-answering system using LangChain.\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "This project aims to build a chatbot that leverages GPT4 to search for answers within documents. The workflow for the experiment is explained in the following diagram:\n",
    "<br/>\n",
    "<img src=\"../../images/chatbot-workflow.png\" alt=\"Chatbot Workflow\" style=\"width: 70%; height: auto;\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_type = os.environ.get(\"OPENAI_API_TYPE\")\n",
    "openai.api_base = os.environ.get(\"OPENAI_API_BASE\")\n",
    "openai.api_version = os.environ.get(\"OPENAI_API_VERSION\")\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.document_loaders import SeleniumURLLoader\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The database for our chatbot will consist of articles regarding technical issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll use information from the following articles\n",
    "urls = [\n",
    "    \"https://beebom.com/what-is-nft-explained/\",\n",
    "    \"https://beebom.com/how-delete-spotify-account/\",\n",
    "    \"https://beebom.com/how-download-gif-twitter/\",\n",
    "    \"https://beebom.com/how-use-chatgpt-linux-terminal/\",\n",
    "    \"https://beebom.com/how-delete-spotify-account/\",\n",
    "    \"https://beebom.com/how-save-instagram-story-with-music/\",\n",
    "    \"https://beebom.com/how-install-pip-windows/\",\n",
    "    \"https://beebom.com/how-check-disk-usage-linux/\",\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Split the documents into chunks and compute their embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the documents from the provided URLs and split them into chunks using the `CharacterTextSplitter` with a chunk size of 1000 and no overlap:\n",
    "\n",
    "> Note: Please provide the full path to your browser executable file in `binary_location`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the selenium scraper to load the documents\n",
    "loader = SeleniumURLLoader(\n",
    "    urls=urls, binary_location=os.environ.get(\"BROWSER_EXEC_PATH\")\n",
    ")\n",
    "docs_not_splitted = loader.load()\n",
    "\n",
    "# we split the documents into smaller chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(docs_not_splitted)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute the embeddings using `HuggingFaceEmbeddings` and store them in a Deep Lake vector store on the cloud. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "# create Deep Lake dataset\n",
    "# TODO: use your organization id here. (by default, org id is your username)\n",
    "my_activeloop_org_id = os.environ.get(\"ACTIVELOOP_ORG_ID\")\n",
    "my_activeloop_dataset_name = \"customer_support\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)\n",
    "\n",
    "# add documents to our Deep Lake dataset\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve the most similar chunks to a given query, we can use the `similarity_search` method of the Deep Lake vector store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home  Tech  How to Check Disk Usage in Linux (4 Methods)\n",
      "\n",
      "How to Check Disk Usage in Linux (4 Methods)\n",
      "\n",
      "Beebom Staff\n",
      "\n",
      "Last Updated: June 19, 2023 5:14 pm\n",
      "\n",
      "There may be times when you need to download some important files or transfer some photos to your Linux system, but face a problem of insufficient disk space. You head over to your file manager to delete the large files which you no longer require, but you have no clue which of them are occupying most of your disk space. In this article, we will show some easy methods to check disk usage in Linux from both the terminal and the GUI application.\n",
      "\n",
      "Monitor Disk Usage in Linux (2023)\n",
      "\n",
      "Table of Contents\n",
      "\n",
      "Check Disk Space Using the df Command\n",
      "\t\t\n",
      "Display Disk Usage in Human Readable FormatDisplay Disk Occupancy of a Particular Type\n",
      "\n",
      "Check Disk Usage using the du Command\n",
      "\t\t\n",
      "Display Disk Usage in Human Readable FormatDisplay Disk Usage for a Particular DirectoryCompare Disk Usage of Two Directories\n"
     ]
    }
   ],
   "source": [
    "# let's see the top relevant documents to a specific query\n",
    "query = \"how to check disk usage in linux?\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Craft a prompt for GPT-4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a prompt template that incorporates role-prompting, relevant Knowledge Base information, and the user's question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's write a prompt for a customer support chatbot that\n",
    "# answer questions using information extracted from our db\n",
    "template = \"\"\"You are an exceptional customer support chatbot that gently answer questions.\n",
    "\n",
    "You know the following context information.\n",
    "\n",
    "{chunks_formatted}\n",
    "\n",
    "Answer to the following question from a customer. Use only information from the previous context \\\n",
    "information. Do not invent stuff.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chunks_formatted\", \"query\"],\n",
    "    template=template,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Utilize the GPT4 model with a temperature of 0 for text generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 The Manual Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To check disk usage in Linux, you can use one of the following methods:\n",
      "\n",
      "1. Using the df command: Open the terminal and type \"df\" to display disk space usage for all mounted filesystems. You can also use \"df -h\" to display the output in a human-readable format.\n",
      "\n",
      "2. Using the du command: In the terminal, type \"du\" to display disk usage for a specific directory. You can use \"du -h\" for a human-readable format or \"du -h /path/to/directory\" to check disk usage for a particular directory.\n",
      "\n",
      "3. Using Gnome Disk Tool: Install the Gnome Disk Tool using \"sudo apt-get -y install gnome-disk-utility\". Open the tool, and click on a partition's name to view details such as device name, file system type, and available space.\n",
      "\n",
      "4. Using Disk Usage Analyzer Tool: Install the tool using \"sudo snap install gdu-disk-usage-analyzer\". Access it via the Applications menu, and click on a device name to view a ring chart of disk occupancy for all folders.\n",
      "\n",
      "Remember to choose the method that best suits your needs and comfort level with the command line or graphical user interface.\n"
     ]
    }
   ],
   "source": [
    "# the full pipeline\n",
    "\n",
    "# user question\n",
    "query = \"How to check disk usage in linux?\"\n",
    "\n",
    "# retrieve relevant chunks\n",
    "docs = db.similarity_search(query)\n",
    "retrieved_chunks = [doc.page_content for doc in docs]\n",
    "\n",
    "# format the prompt\n",
    "chunks_formatted = \"\\n\\n\".join(retrieved_chunks)\n",
    "prompt_formatted = prompt.format(chunks_formatted=chunks_formatted, query=query)\n",
    "\n",
    "# generate answer\n",
    "llm = AzureChatOpenAI(deployment_name=\"gpt4\", temperature=0)\n",
    "answer = llm.predict(prompt_formatted)\n",
    "print(answer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 The Automated Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "There are several methods to check disk usage in Linux, both from the terminal and using GUI applications. Here are some common methods:\n",
       "\n",
       "1. Using the df command in the terminal:\n",
       "To check disk space, open the terminal and type the following command:\n",
       "\n",
       "```\n",
       "df\n",
       "```\n",
       "\n",
       "To display disk usage in a human-readable format, use the -h flag:\n",
       "\n",
       "```\n",
       "df -h\n",
       "```\n",
       "\n",
       "2. Using the du command in the terminal:\n",
       "To check disk usage for a particular directory, use the following command:\n",
       "\n",
       "```\n",
       "du /path/to/directory\n",
       "```\n",
       "\n",
       "To display disk usage in a human-readable format, use the -h flag:\n",
       "\n",
       "```\n",
       "du -h /path/to/directory\n",
       "```\n",
       "\n",
       "3. Using the Gnome Disk Tool (GUI):\n",
       "First, install the Gnome Disk Tool using the following command:\n",
       "\n",
       "```\n",
       "sudo apt-get -y install gnome-disk-utility\n",
       "```\n",
       "\n",
       "Open the Gnome Disk Tool, and click on the partition's name to view details such as device name, file system type, and available space.\n",
       "\n",
       "4. Using the Disk Usage Analyzer Tool (GUI):\n",
       "Install the Disk Usage Analyzer using the following command:\n",
       "\n",
       "```\n",
       "sudo snap install gdu-disk-usage-analyzer\n",
       "```\n",
       "\n",
       "Open the Disk Usage Analyzer tool from the Applications menu. It will show all the storage partitions connected to your system along with your Home directory. Click on the device name to view a ring chart of the disk occupancy for all the folders."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=db.as_retriever(),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "response = qa_stuff.run(query)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issue with Generating Answers using LLMs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-4 is less likely to generate false information when the answer to the user's question is contained within the context. But what if the answer is not contained within the context? In this case, GPT-4 might make things up (**hallucination**). Since user questions are often brief and ambiguous, we cannot always rely on the semantic search step to retrieve the correct document. Thus, there is always a risk of generating false information.\n",
    "\n",
    "To mimimize this we can write better prompts by adding the following statement when there is not enough information in the context: `Say \"I don't have enough information.\" if you don't have enough information in the context to answer the question.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an exceptional customer support chatbot that gently answer questions.\n",
    "\n",
    "You know the following context information.\n",
    "\n",
    "{chunks_formatted}\n",
    "\n",
    "Answer to the following question from a customer. Use only information from the previous context \\\n",
    "information. Do not invent stuff. Say \"I don't have enough information.\" if you don't have enough \\\n",
    "information in the context to answer the question.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
