{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Graph: Unveiling Hidden Connections\n",
    "In today's data-driven world, understanding the relationships between different pieces of information is crucial. Knowledge graphs have emerged as a powerful way to visualize and explore these connections, transforming unstructured text into a structured network of entities and their relationships. We will go through a simple workflow for creating a knowledge graph from textual data, making complex information more accessible and easier to understand.\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Graphs: 101"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Graphs and Knowledge Bases: Difference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The terms \"knowledge graph\" and \"knowledge base\" are often used interchangeably, but they have subtle differences. Knowledge base (KB) refers to structured information that we have about a domain of interest. On the other hand, a knowledge graph is a knowledge base structured as a graph, where nodes represent entities and edges signify relations between those entities. For example, from the text \"Alice lives in Wonderland\", we can extract the relation triplet `<Alice, lives in, Wonderland>`, where \"Alice\" and \"Wonderland\" are entities, and \"lives in\" is relation between them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Knowledge Graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of building a knowledge graph usually consists of two sequential steps:\n",
    "- **Named Entity Recognition** (NER): This step involves extracting entities from the text, which will eventually become the nodes of the knowledge graph.\n",
    "- **Relation Classification** (RC): In this step, relations between entities are extracted, forming the edges of the knowledge graph.\n",
    "\n",
    "Then, the knowledge graph is commonly visualized using libraries such as `pyvis`. In this project, we'll do the Named Entity Recognition and Relation Classification tasks simultaneously with an appropriate prompt. This joint task is commonly called **Relation Extraction** (RE)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow for Creating Knowledge Graphs from Textual Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hereâ€™s what we are going to do in this project.\n",
    "<br/>\n",
    "<img src=\"../../images/knowledge-graph-workflow.png\" alt=\"Knowledge Graph Workflow\" style=\"width: 80%; height: auto;\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_type = os.environ.get(\"OPENAI_API_TYPE\")\n",
    "openai.api_base = os.environ.get(\"OPENAI_API_BASE\")\n",
    "openai.api_version = os.environ.get(\"OPENAI_API_VERSION\")\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Knowledge Graph with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Paris, is, capital of France)<|>(Paris, is, most populous city of France)<|>(Eiffel Tower, is, famous landmark in Paris)\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.graphs.networkx_graph import KG_TRIPLE_DELIMITER\n",
    "\n",
    "# Prompt template for knowledge triple extraction\n",
    "_DEFAULT_KNOWLEDGE_TRIPLE_EXTRACTION_TEMPLATE = (\n",
    "    \"You are a networked intelligence helping a human track knowledge triples\"\n",
    "    \" about all relevant people, things, concepts, etc. and integrating\"\n",
    "    \" them with your knowledge stored within your weights\"\n",
    "    \" as well as that stored in a knowledge graph.\"\n",
    "    \" Extract all of the knowledge triples from the text.\"\n",
    "    \" A knowledge triple is a clause that contains a subject, a predicate,\"\n",
    "    \" and an object. The subject is the entity being described,\"\n",
    "    \" the predicate is the property of the subject that is being\"\n",
    "    \" described, and the object is the value of the property.\\n\\n\"\n",
    "    \"EXAMPLE\\n\"\n",
    "    \"It's a state in the US. It's also the number 1 producer of gold in the US.\\n\\n\"\n",
    "    f\"Output: (Nevada, is a, state){KG_TRIPLE_DELIMITER}(Nevada, is in, US)\"\n",
    "    f\"{KG_TRIPLE_DELIMITER}(Nevada, is the number 1 producer of, gold)\\n\"\n",
    "    \"END OF EXAMPLE\\n\\n\"\n",
    "    \"EXAMPLE\\n\"\n",
    "    \"I'm going to the store.\\n\\n\"\n",
    "    \"Output: NONE\\n\"\n",
    "    \"END OF EXAMPLE\\n\\n\"\n",
    "    \"EXAMPLE\\n\"\n",
    "    \"Oh huh. I know Descartes likes to drive antique scooters and play the mandolin.\\n\"\n",
    "    f\"Output: (Descartes, likes to drive, antique scooters){KG_TRIPLE_DELIMITER}(Descartes, plays, mandolin)\\n\"\n",
    "    \"END OF EXAMPLE\\n\\n\"\n",
    "    \"EXAMPLE\\n\"\n",
    "    \"{text}\"\n",
    "    \"Output:\"\n",
    ")\n",
    "\n",
    "KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=_DEFAULT_KNOWLEDGE_TRIPLE_EXTRACTION_TEMPLATE,\n",
    ")\n",
    "\n",
    "model = AzureChatOpenAI(deployment_name=\"gpt4\", temperature=0.9)\n",
    "\n",
    "# Create an LLMChain using the knowledge triple extraction prompt\n",
    "chain = LLMChain(llm=model, prompt=KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT)\n",
    "\n",
    "# Run the chain with the specified text\n",
    "text = \"The city of Paris is the capital and most populous city of France. \\\n",
    "The Eiffel Tower is a famous landmark in Paris.\"\n",
    "\n",
    "triples = chain.run(text)\n",
    "\n",
    "print(triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(Paris, is, capital of France)', '(Paris, is, most populous city of France)', '(Eiffel Tower, is, famous landmark in Paris)']\n"
     ]
    }
   ],
   "source": [
    "# Extract the triplets from the response into a list\n",
    "\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def parse_triples(response: str, delimiter: str = KG_TRIPLE_DELIMITER) -> List[str]:\n",
    "    if not response:\n",
    "        return []\n",
    "    return response.split(delimiter)\n",
    "\n",
    "\n",
    "triples_list = parse_triples(triples)\n",
    "print(triples_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Graph Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knowledge_graph.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"knowledge_graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x213811c6550>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "from typing import List\n",
    "\n",
    "# Create a NetworkX graph from the extracted relation triplets\n",
    "def create_graph_from_triplets(triplets: List[str]) -> nx.DiGraph:\n",
    "    G = nx.DiGraph()\n",
    "    for triplet in triplets:\n",
    "        subject, predicate, obj = triplet.strip().split(\",\")\n",
    "        G.add_edge(subject.strip(), obj.strip(), label=predicate.strip())\n",
    "    return G\n",
    "\n",
    "\n",
    "# Convert the NetworkX graph to a PyVis network\n",
    "def nx_to_pyvis(networkx_graph: nx.DiGraph) -> Network:\n",
    "    pyvis_graph = Network(notebook=True, cdn_resources=\"in_line\")\n",
    "    for node in networkx_graph.nodes():\n",
    "        pyvis_graph.add_node(node)\n",
    "    for edge in networkx_graph.edges(data=True):\n",
    "        pyvis_graph.add_edge(edge[0], edge[1], label=edge[2][\"label\"])\n",
    "    return pyvis_graph\n",
    "\n",
    "\n",
    "triplets = [t.strip() for t in triples_list if t.strip()]\n",
    "graph = create_graph_from_triplets(triplets)\n",
    "pyvis_network = nx_to_pyvis(graph)\n",
    "\n",
    "# Customize the appearance of the graph\n",
    "pyvis_network.toggle_hide_edges_on_drag(True)\n",
    "pyvis_network.toggle_physics(False)\n",
    "pyvis_network.set_edge_smooth(\"discrete\")\n",
    "\n",
    "# Show the interactive knowledge graph visualization\n",
    "pyvis_network.show(\"knowledge_graph.html\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** It's worth noting that LangChain offers the `GraphIndexCreator` class, which automates the extraction of relation triplets and is seamlessly integrated with question-answering chains. In future articles, we'll delve deeper into this powerful feature, showcasing its potential further to enhance knowledge graph creation and analysis capabilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
