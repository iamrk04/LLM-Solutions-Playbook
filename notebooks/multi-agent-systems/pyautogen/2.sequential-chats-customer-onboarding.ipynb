{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Chats and Customer Onboarding\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create conda env using the following command from the root of this repo: `conda env create -f ./notebooks/multi-agent-systems/pyautogen/conda-env.yaml`.\n",
    "- Please define the following environment variables in `.env` file:\n",
    "    - `OPENAI_API_BASE=\"<ENDPOINT_URL>\"`\n",
    "    - `OPENAI_API_KEY=\"<API_KEY>\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/cust-onboarding-overview.png\" alt=\"Customer Onboarding Overview\" style=\"width: 40%;\"/>\n",
    "<img src=\"./images/cust-onboarding-detailed.png\" alt=\"Customer Onboarding Detailed\" style=\"width: 40%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please find additional info about how to create LLM Configuration [over here](https://microsoft.github.io/autogen/docs/topics/llm_configuration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"model\": \"gpt-4-turbo\",\n",
    "    \"api_type\": \"azure\",\n",
    "    \"base_url\": os.environ.get(\"OPENAI_API_BASE\"),\n",
    "    \"api_key\": os.environ.get(\"OPENAI_API_KEY\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the needed agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_personal_information_agent = ConversableAgent(\n",
    "    name=\"Onboarding_Personal_Information_Agent\",  # do not use spaces in agent name, throws error\n",
    "    system_message='''You are a helpful customer onboarding agent,\n",
    "    you are here to help new customers get started with our product.\n",
    "    Your job is to gather customer's name and location.\n",
    "    Do not ask for other information. Return 'TERMINATE' \n",
    "    when you have gathered all the information.''',\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_topic_preference_agent = ConversableAgent(\n",
    "    name=\"Onboarding_Topic_preference_Agent\",\n",
    "    system_message='''You are a helpful customer onboarding agent,\n",
    "    you are here to help new customers get started with our product.\n",
    "    Your job is to gather customer's preferences on news topics.\n",
    "    Do not ask for other information.\n",
    "    Return 'TERMINATE' when you have gathered all the information.''',\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_engagement_agent = ConversableAgent(\n",
    "    name=\"Customer_Engagement_Agent\",\n",
    "    system_message='''You are a helpful customer service agent\n",
    "    here to provide fun for the customer based on the user's\n",
    "    personal information and topic preferences.\n",
    "    This could include fun facts, jokes, or interesting stories.\n",
    "    Make sure to make it engaging and fun!\n",
    "    Return 'TERMINATE' when you are done.''',\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"terminate\" in msg.get(\"content\").lower(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_proxy_agent = ConversableAgent(\n",
    "    name=\"customer_proxy_agent\",\n",
    "    llm_config=False,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"ALWAYS\",\n",
    "    is_termination_msg=lambda msg: \"terminate\" in msg.get(\"content\").lower(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "chats = [\n",
    "    {\n",
    "        \"sender\": onboarding_personal_information_agent,\n",
    "        \"recipient\": customer_proxy_agent,\n",
    "        \"message\": \"Hello, I'm here to help you get started with our product. \"\n",
    "        \"Could you tell me your name and location?\",\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "        \"summary_args\": {\n",
    "            \"summary_prompt\": \"Return the customer information \"\n",
    "            \"into as JSON object only: \"\n",
    "            \"{'name': '', 'location': ''}\",\n",
    "        },\n",
    "        \"max_turns\": 2,\n",
    "        \"clear_history\": True,\n",
    "    },\n",
    "    {\n",
    "        \"sender\": onboarding_topic_preference_agent,\n",
    "        \"recipient\": customer_proxy_agent,\n",
    "        \"message\": \"Great! Could you tell me what topics you are \"\n",
    "        \"interested in reading about?\",\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "        \"max_turns\": 1,\n",
    "        \"clear_history\": False,\n",
    "    },\n",
    "    {\n",
    "        \"sender\": customer_proxy_agent,\n",
    "        \"recipient\": customer_engagement_agent,\n",
    "        \"message\": \"Let's find something fun to read.\",\n",
    "        \"max_turns\": 1,\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the onboarding process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mOnboarding_Personal_Information_Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Hello, I'm here to help you get started with our product. Could you tell me your name and location?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Onboarding_Personal_Information_Agent):\n",
      "\n",
      "Andy\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mOnboarding_Personal_Information_Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Thank you, Andy. Could you please provide your location as well?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Onboarding_Personal_Information_Agent):\n",
      "\n",
      "Bangalore\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mOnboarding_Topic_preference_Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Great! Could you tell me what topics you are interested in reading about?\n",
      "Context: \n",
      "{\n",
      "  \"name\": \"Andy\",\n",
      "  \"location\": \"Bangalore\"\n",
      "}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Onboarding_Topic_preference_Agent):\n",
      "\n",
      "Dog\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Customer_Engagement_Agent):\n",
      "\n",
      "Let's find something fun to read.\n",
      "Context: \n",
      "{\n",
      "  \"name\": \"Andy\",\n",
      "  \"location\": \"Bangalore\"\n",
      "}\n",
      "Andy, located in Bangalore, is interested in reading about dogs.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCustomer_Engagement_Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Hello Andy! Thanks for sharing your interest in dogs. Since you're in Bangalore, how about we explore some intriguing dog facts suited to your locale? Here's something fun:\n",
      "\n",
      "Did you know that one of the most popular dog breeds in Bangalore is the Labrador Retriever? Not only are they great family pets, but they're also known for their intelligence and helping abilities. Labs have been trained in Bangalore to support various services, including assistance for the disabled and therapy work.\n",
      "\n",
      "And here’s a delightful little joke to lighten up your day:\n",
      "Why did the dog sit in the shade?\n",
      "Because he didn’t want to be a hot dog!\n",
      "\n",
      "Let me know if you'd like more facts or if you have any specific dog-related topics in mind!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from autogen import initiate_chats\n",
    "\n",
    "chat_results = initiate_chats(chats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Andy\",\n",
      "  \"location\": \"Bangalore\"\n",
      "}\n",
      "\n",
      "\n",
      "Andy, located in Bangalore, is interested in reading about dogs.\n",
      "\n",
      "\n",
      "Andy from Bangalore is interested in reading about dogs, and a suggestion was made about the popularity of Labrador Retrievers in Bangalore, highlighting their roles as family pets and service dogs. Additionally, a light-hearted joke about a dog was shared to entertain Andy.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chat_result in chat_results:\n",
    "    print(chat_result.summary)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out the cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'usage_including_cached_inference': {'total_cost': 0.0063, 'gpt-4-turbo-2024-04-09': {'cost': 0.0063, 'prompt_tokens': 444, 'completion_tokens': 62, 'total_tokens': 506}}, 'usage_excluding_cached_inference': {'total_cost': 0}}\n",
      "\n",
      "\n",
      "{'usage_including_cached_inference': {'total_cost': 0.0027700000000000003, 'gpt-4-turbo-2024-04-09': {'cost': 0.0027700000000000003, 'prompt_tokens': 214, 'completion_tokens': 21, 'total_tokens': 235}}, 'usage_excluding_cached_inference': {'total_cost': 0.0027700000000000003, 'gpt-4-turbo-2024-04-09': {'cost': 0.0027700000000000003, 'prompt_tokens': 214, 'completion_tokens': 21, 'total_tokens': 235}}}\n",
      "\n",
      "\n",
      "{'usage_including_cached_inference': {'total_cost': 0.0161, 'gpt-4-turbo-2024-04-09': {'cost': 0.0161, 'prompt_tokens': 467, 'completion_tokens': 381, 'total_tokens': 848}}, 'usage_excluding_cached_inference': {'total_cost': 0.0161, 'gpt-4-turbo-2024-04-09': {'cost': 0.0161, 'prompt_tokens': 467, 'completion_tokens': 381, 'total_tokens': 848}}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chat_result in chat_results:\n",
    "    print(chat_result.cost)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
