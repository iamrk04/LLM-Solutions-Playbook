{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent Conversation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create conda env using the following command from the root of this repo: `conda env create -f ./notebooks/multi-agent-systems/pyautogen/conda-env.yaml`.\n",
    "- Please define the following environment variables in `.env` file:\n",
    "    - `OPENAI_API_BASE=\"<ENDPOINT_URL>\"`\n",
    "    - `OPENAI_API_KEY=\"<API_KEY>\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please find additional info about how to create LLM Configuration [over here](https://microsoft.github.io/autogen/docs/topics/llm_configuration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"model\": \"gpt-4-turbo\",\n",
    "    \"api_type\": \"azure\",\n",
    "    \"base_url\": os.environ.get(\"OPENAI_API_BASE\"),\n",
    "    \"api_key\": os.environ.get(\"OPENAI_API_KEY\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define an AutoGen agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent\n",
    "\n",
    "agent = ConversableAgent(\n",
    "    name=\"chatbot\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't skeletons fight each other?\n",
      "\n",
      "They don't have the guts.\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(\n",
    "    messages=[{\"content\": \"Tell me a joke.\", \"role\": \"user\"}]\n",
    ")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, method `generate_reply` does not remember the previous conversation context. This is because this method does not maintain state between calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd be happy to share a joke, but I need a little more context. Was there a specific joke you had in mind, or would you like me to come up with a new one for you?\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(\n",
    "    messages=[{\"content\": \"Repeat the joke.\", \"role\": \"user\"}]\n",
    ")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up a conversation between two agents, Cathy and Joe, where the memory of their interactions is retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \"\n",
    "    \"Start the next joke from the punchline of the previous joke.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Hey Joe! I'm ready to bring the laughs. You know, they say laughter is the best medicine, which is great because have you seen my health insurance premiums lately? üòÇ What‚Äôs new with you?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Haha, Cathy, my health insurance premiums are so high, I need a side hustle just to afford the deductible! Speaking of side hustles, I recently taught my dog how to fetch the newspaper. Now, I‚Äôm trying to teach him to negotiate for a lower price!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, Joe, that‚Äôs a smart move! With those negotiation skills, maybe next you can teach him to bark in \"discount\" language. Soon enough, he'll be fetching you deals and coupons instead of just the paper. üòÑ Just don't let him near your credit cards, or he might start shopping for bones online!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy, \n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\",\n",
    "    max_turns=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print some results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can print out:\n",
    "- Chat history\n",
    "- Cost\n",
    "- Summary of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': \"I'm Joe. Cathy, let's keep the jokes rolling.\",\n",
      "  'name': 'joe',\n",
      "  'role': 'assistant'},\n",
      " {'content': \"Hey Joe! I'm ready to bring the laughs. You know, they say \"\n",
      "             'laughter is the best medicine, which is great because have you '\n",
      "             'seen my health insurance premiums lately? üòÇ What‚Äôs new with you?',\n",
      "  'name': 'cathy',\n",
      "  'role': 'user'},\n",
      " {'content': 'Haha, Cathy, my health insurance premiums are so high, I need a '\n",
      "             'side hustle just to afford the deductible! Speaking of side '\n",
      "             'hustles, I recently taught my dog how to fetch the newspaper. '\n",
      "             'Now, I‚Äôm trying to teach him to negotiate for a lower price!',\n",
      "  'name': 'joe',\n",
      "  'role': 'assistant'},\n",
      " {'content': 'Haha, Joe, that‚Äôs a smart move! With those negotiation skills, '\n",
      "             'maybe next you can teach him to bark in \"discount\" language. '\n",
      "             \"Soon enough, he'll be fetching you deals and coupons instead of \"\n",
      "             \"just the paper. üòÑ Just don't let him near your credit cards, or \"\n",
      "             'he might start shopping for bones online!',\n",
      "  'name': 'cathy',\n",
      "  'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(chat_result.chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'usage_excluding_cached_inference': {'gpt-4-turbo-2024-04-09': {'completion_tokens': 167,\n",
      "                                                                 'cost': 0.00788,\n",
      "                                                                 'prompt_tokens': 287,\n",
      "                                                                 'total_tokens': 454},\n",
      "                                      'total_cost': 0.00788},\n",
      " 'usage_including_cached_inference': {'gpt-4-turbo-2024-04-09': {'completion_tokens': 167,\n",
      "                                                                 'cost': 0.00788,\n",
      "                                                                 'prompt_tokens': 287,\n",
      "                                                                 'total_tokens': 454},\n",
      "                                      'total_cost': 0.00788}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Haha, Joe, that‚Äôs a smart move! With those negotiation skills, maybe next '\n",
      " 'you can teach him to bark in \"discount\" language. Soon enough, he\\'ll be '\n",
      " \"fetching you deals and coupons instead of just the paper. üòÑ Just don't let \"\n",
      " 'him near your credit cards, or he might start shopping for bones online!')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a better summary of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Hey Joe! I'm ready to bring the laughs. You know, they say laughter is the best medicine, which is great because have you seen my health insurance premiums lately? üòÇ What‚Äôs new with you?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Haha, Cathy, my health insurance premiums are so high, I need a side hustle just to afford the deductible! Speaking of side hustles, I recently taught my dog how to fetch the newspaper. Now, I‚Äôm trying to teach him to negotiate for a lower price!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, Joe, that‚Äôs a smart move! With those negotiation skills, maybe next you can teach him to bark in \"discount\" language. Soon enough, he'll be fetching you deals and coupons instead of just the paper. üòÑ Just don't let him near your credit cards, or he might start shopping for bones online!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    cathy, \n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\", \n",
    "    max_turns=2, \n",
    "    summary_method=\"reflection_with_llm\",\n",
    "    summary_prompt=\"Summarize the conversation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: Please note that the cached result was used for the conversation because the input was same. The models was called only for the generation of summary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Joe and Cathy are exchanging jokes about high health insurance premiums and '\n",
      " 'the amusing idea of teaching a dog to fetch newspapers and negotiate for '\n",
      " 'better deals.')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Termination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"],\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"] or \"Goodbye\" in msg[\"content\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Hey Joe! Nice to meet you. I'm always ready with a joke or two up my sleeve. What do you call fake spaghetti? An impasta! üòÑ What about you, got any good jokes to share?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Hey Cathy! Nice one, that was quite al-dente! üòÑ Here‚Äôs one for you: Why don't skeletons fight each other? They don't have the guts! Got any more? Let‚Äôs keep the laughter going!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, that was spine-tinglingly funny, Joe! Here's another one: Why can't you give Elsa a balloon? Because she will let it go! üéà Your turn, keep the funny bone tickles coming!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Oh, Cathy, that one was chillingly good! Here‚Äôs another: What do you call cheese that isn't yours? Nacho cheese! üòÜ Hit me with your best shot, let‚Äôs see what you‚Äôve got!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Oh, Joe, that one was extra cheesy! Here‚Äôs one for you: Why don't oysters donate to charity? Because they're shellfish! üòÇ Alright, your turn‚Äîlet‚Äôs make it a laughter feast!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Such a shell-arious joke, Cathy! Here's one for you: Why did the golfer bring two pairs of pants? In case he got a hole in one! Keep them coming, we're on a roll! üòÑ\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, Joe, that's a hole lot of foresight! Okay, here‚Äôs another: What do you call an alligator in a vest? An investigator! üòÅ I'm having a great time, but I gotta go. Keep the laughs rolling wherever you are, Joe! Bye!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy,\n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "What's last joke we talked about?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "The last joke was about the alligator: \"What do you call an alligator in a vest? An investigator!\" üòÅ Great one, Cathy! Do you have more jokes, or should I take a swing at it?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Actually, I gotta go, Joe! Keep swinging those jokes, and keep the laughter alive. Catch you later! Bye!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cathy.send(message=\"What's last joke we talked about?\", recipient=joe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
