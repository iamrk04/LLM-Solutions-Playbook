{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training LLM from scratch\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to train LLM from scratch?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are not getting the desired output, these are the following things that should be tried in order:\n",
    "1. **Prompt Engineering**: Use a better prompt.\n",
    "2. **Few-shot (In-Context) Learning**: Use few-shot examples and/or RAG.\n",
    "3. **Finetuning**: It can improve model understanding by providing more examples and adjusting weights. Excellent option for creating a model with task-specific knowledge (proprietary knowledge) and building on top of the available powerful LLMs. Although finetuning can be challenging when acquiring new knowledge, it is more effective in adapting to different styles, and tones, or incorporating new vocabulary.\n",
    "4. **Training from scratch**: If fine-tuning is not effective, consider training a model from scratch with domain-specific data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMOps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps involved in LLMOps:\n",
    "1. **Selection of a Foundation Model**: Proprietary vs Open Source models. Then choosing a suitable model from the selected category.\n",
    "2. **Adaptation to Downstream Tasks**: Prompt Engineering, Few-shot Learning, Finetuning, Training from scratch.\n",
    "3. **Evaluation**: Evaluating the performance of an LLM is more complex than evaluating traditional ML models. The main reason for this is that the output of an LLM is usually free text, and it’s harder to devise metrics that can be computed via code and that work well on free text.\n",
    "4. **Deployment and Monitoring**: Deploying and monitoring LLMs is very important as their completions can change significantly between releases. Another concern about LLMOps is the latency of the model.\n",
    "\n",
    "> Note: It's important to keep track of the prompts used when using prompt engineering since they will likely be improved over time and can impact performance on specific tasks. By doing this, if a new prompt in production works worse than the previous one in some aspects and If we want to revert, it can be done easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the Training Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "Curating a comprehensive database containing relevant information is the most crucial step. There are several well-known databases that you can use as a source of public knowledge. For instance, consider datasets like [The Pile](https://pile.eleuther.ai/), [Common Crawl](https://commoncrawl.org/), or [Wikipedia](https://dumps.wikimedia.org/), which entail extensive collections of web pages, articles, or books.\n",
    "\n",
    "The next category of datasets is important only if you are training a model for a specific use case based on the data your organization has at hand or curated. Note that the size of your dataset may vary depending on your application and whether you opt for fine-tuning or training from scratch.The data source can be obtained through web scraping of news websites, forums, or publicly accessible databases, in addition to leveraging your own private knowledge base. It’s also possible to use a foundational LLM to generate a synthetic dataset of your own to be used for training a specialised domain LLM, which may be less expensive and faster than the big foundational model.\n",
    "\n",
    "Splitting the dataset into training and validation sets is a standard process. The training set is utilized during the training process to optimize the model's parameters. On the other hand, the validation set is used to assess the model's performance and ensure it is not overfitting by evaluating its generalization ability.\n",
    "\n",
    "### Model\n",
    "The transformer has been the dominant network architecture for natural language processing tasks in recent years. It is powered by the attention mechanism, which enables the models to accurately identify the relationship between words.\n",
    "\n",
    "### Training\n",
    "The first generation of foundational models like BERT were trained with Masked Language Modeling (MLM) learning objectives. This is achieved by randomly masking words from the corpus and configuring the model to predict the masked word. By employing this objective, the model gains the ability to consider the contextual information preceding and following the masked word, enabling it to make informed decisions.\n",
    "\n",
    "The GPT family models used the Autoregressive learning objective. This algorithm ensures that the model consistently attempts to predict the next word without accessing the future content within the corpus. The training process will be iterative, which feeds back the generated tokens to the model to predict the next word. Masked attention ensures that, at each time step, the model is prevented from seeing future words.\n",
    "\n",
    "To train or finetune models, you have the option to either implement the training loop using libraries such as PyTorch or utilize the `Trainer` class provided by Huggingface. The latter option enables us to easily configure different hyperparameters, log, save checkpoints, and evaluate the model."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
